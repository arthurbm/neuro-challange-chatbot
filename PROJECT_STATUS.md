# ğŸ“‹ Status do Projeto - Credit Analytics Chatbot

## âœ… Componentes Implementados

### 1. Infraestrutura e Setup
- [x] **Docker Compose** - Postgres + pgAdmin para desenvolvimento local
- [x] **Estrutura de diretÃ³rios** completa
- [x] **pyproject.toml** atualizado com todas as dependÃªncias (gerenciado por `uv`)
- [x] **.gitignore** completo
- [x] **.env.example** com documentaÃ§Ã£o de variÃ¡veis
- [x] **README.md** detalhado com instruÃ§Ãµes completas

### 2. MÃ³dulos Core
- [x] **src/config.py** - ConfiguraÃ§Ãµes centralizadas com Pydantic Settings
  - Database config (RDS/local)
  - LLM config (OpenAI/OpenRouter)
  - LangSmith config (tracing)
  - Guardrails config (k-anonimato, timeouts, limites)
  - Formatting config (PT-BR)

- [x] **src/utils/sql_validator.py** - ValidaÃ§Ã£o SQL com sqlglot
  - ValidaÃ§Ã£o de sintaxe
  - Bloqueio de DDL/DML (read-only enforcement)
  - AplicaÃ§Ã£o de guardrails (LIMIT padrÃ£o)
  - FormataÃ§Ã£o SQL

- [x] **src/utils/business_dictionary.py** - DicionÃ¡rio de negÃ³cio
  - MÃ©tricas canÃ´nicas (inadimplÃªncia, volume, idade, etc.)
  - DimensÃµes (UF, sexo, classe social, idade, Ã³bito)
  - AgregaÃ§Ãµes temporais (mensal, anual)
  - Exemplos few-shot para o LLM
  - Schema completo da tabela

- [x] **src/utils/db_connection.py** - Gerenciador de conexÃµes
  - Pool de conexÃµes com SQLAlchemy
  - Statement timeout configurÃ¡vel
  - Context manager para conexÃµes
  - Helpers para queries e info de tabelas

### 3. Tools Implementadas
- [x] **src/tools/database_query_tool.py** - Tool de consulta SQL âœ…
  - GeraÃ§Ã£o de SQL a partir de linguagem natural usando LLM
  - ValidaÃ§Ã£o com sql_validator
  - Sistema de retry com auto-correÃ§Ã£o (atÃ© 3 tentativas)
  - FormataÃ§Ã£o de resposta em PT-BR
  - Logging e tracing com LangSmith

- [x] **src/tools/visualization_tool.py** - Tool de visualizaÃ§Ã£o âœ…
  - GrÃ¡ficos matplotlib com formataÃ§Ã£o PT-BR
  - Tipos suportados: bar, line, histogram, pie
  - Auto-detecÃ§Ã£o de tipo de grÃ¡fico
  - **Usa `response_format="content_and_artifact"` para eficiÃªncia de tokens**
  - Content: ~10 tokens (mensagem curta)
  - Artifact: ~119k chars base64 (NÃƒO enviado ao modelo, economiza ~$0.0012/imagem)
  - Agent Chat UI renderiza artifact automaticamente no painel lateral
  - Labels formatados (%, n, vÃ­rgula decimal)

### 4. Agente LangChain
- [x] **src/agent.py** - Agente principal âœ…
  - Criado com create_agent (LangChain 1.0)
  - Integrado com query_database e generate_chart
  - System prompt detalhado com instruÃ§Ãµes PT-BR
  - Observabilidade via LangSmith

### 5. Scripts e Utilidades
- [x] **scripts/init_db.sql** - InicializaÃ§Ã£o do banco
  - Schema com colunas em **MAIÃšSCULA** (conforme solicitado)
  - Ãndices otimizados (da EDA)
  - UsuÃ¡rio read-only `chatbot_reader`
  - PermissÃµes restritivas

- [x] **scripts/load_data.py** - Carga de dados
  - Download automÃ¡tico do dataset
  - TransformaÃ§Ãµes (tipos, normalizaÃ§Ã£o)
  - Carga em lotes com progress bar
  - ValidaÃ§Ãµes e estatÃ­sticas

---

## ğŸš§ PrÃ³ximos Passos (Ordem de ImplementaÃ§Ã£o)

### âœ… Fase 1: Tools (Core do Sistema) - CONCLUÃDA

#### âœ… A. Tool `query_database` - IMPLEMENTADA
**Arquivo**: `src/tools/database_query_tool.py`

**Estrutura sugerida**:
```python
from langchain.tools import tool
from langchain_openai import ChatOpenAI
from pydantic import BaseModel, Field

class QueryDatabaseInput(BaseModel):
    """Schema de input para a tool."""
    question_context: str = Field(
        description="Pergunta do usuÃ¡rio em linguagem natural sobre dados de crÃ©dito"
    )

@tool(response_format="content_and_artifact")
def query_database(question_context: str) -> tuple[str, dict]:
    """
    Analisa dados de crÃ©dito executando SQL baseado na pergunta do usuÃ¡rio.

    Fluxo interno:
    1. LLM gera SQL a partir do contexto
    2. Valida com sql_validator
    3. Executa com retry e auto-correÃ§Ã£o
    4. Formata resposta em linguagem natural

    Returns:
        (resposta_formatada_pt_br, metadata_com_sql_e_dados)
    """
    # 1. Gerar SQL com LLM
    sql = _generate_sql_with_llm(question_context)

    # 2. Validar
    is_valid, validated_sql = sql_validator.validate(sql)

    # 3. Executar com retry
    result_data = _execute_with_retry(validated_sql, max_retries=3)

    # 4. Formatar resposta
    formatted_response = _format_response_natural_language(
        question_context, result_data
    )

    # 5. Metadata para artifact
    metadata = {
        "sql": validated_sql,
        "data": result_data,
        "row_count": len(result_data)
    }

    return formatted_response, metadata
```

**Componentes internos**:
- `_generate_sql_with_llm()`: Usa LLM com few-shot examples do business_dict
- `_execute_with_retry()`: Tenta executar, captura erros, usa LLM para corrigir
- `_format_response_natural_language()`: Converte resultados para PT-BR formatado

**DependÃªncias**:
- `from src.utils.sql_validator import sql_validator`
- `from src.utils.business_dictionary import BusinessDictionary`
- `from src.utils.db_connection import db_manager`
- `from src.config import config`

---

#### âœ… B. Tool `generate_chart` - IMPLEMENTADA
**Arquivo**: `src/tools/visualization_tool.py` âœ…

Implementada com sucesso! Features incluÃ­das:

```python
import matplotlib.pyplot as plt
import base64
from io import BytesIO

@tool
def generate_chart(
    data: list[dict],
    chart_type: str = "bar",
    title: str = "GrÃ¡fico"
) -> str:
    """
    Gera visualizaÃ§Ã£o matplotlib e retorna base64 para Agent Chat UI.

    Tipos suportados: bar, line, pie, histogram
    """
    # Criar grÃ¡fico
    fig, ax = plt.subplots(figsize=(10, 6))

    # Plotar baseado no tipo
    # ... (implementaÃ§Ã£o matplotlib)

    # Converter para base64
    buffer = BytesIO()
    plt.savefig(buffer, format='png', dpi=150, bbox_inches='tight')
    buffer.seek(0)
    img_base64 = base64.b64encode(buffer.read()).decode()
    plt.close()

    return f"data:image/png;base64,{img_base64}"
```

---

### Fase 2: Agente LangChain

#### Arquivo: `src/agent.py`

```python
"""
Agente LangChain para anÃ¡lise de dados de crÃ©dito.
"""

from langchain.agents import create_agent
from langchain_openai import ChatOpenAI

from src.config import config
from src.tools.database_query_tool import query_database
# from src.tools.visualization_tool import generate_chart

# Configurar LangSmith
config.setup_langsmith()

# Inicializar modelo
model = ChatOpenAI(
    model=config.llm.model,
    temperature=config.llm.temperature,
    max_tokens=config.llm.max_tokens,
)

# System prompt
SYSTEM_PROMPT = """
VocÃª Ã© um assistente especialista em anÃ¡lise de dados de crÃ©dito brasileiro.

VocÃª tem acesso a uma base de ~170mil registros de concessÃ£o de crÃ©dito (perÃ­odo: 2017-01 a 2017-08).

**Dados disponÃ­veis**:
- REF_DATE: Data de referÃªncia
- TARGET: InadimplÃªncia (0=bom pagador, 1=mau pagador)
- SEXO: M/F
- IDADE: Idade em anos
- OBITO: Indicador de Ã³bito
- UF: Estado brasileiro (27 UFs)
- CLASSE_SOCIAL: alta, mÃ©dia, baixa

**Sua missÃ£o**:
1. Interpretar perguntas do usuÃ¡rio sobre os dados
2. Usar a tool `query_database` para executar anÃ¡lises SQL
3. Responder em portuguÃªs claro e objetivo
4. Explicar insights de forma acessÃ­vel

**DicionÃ¡rio de termos**:
- "inadimplÃªncia" ou "mau pagador" = TARGET=1
- "taxa de inadimplÃªncia" = mÃ©dia do TARGET (em %)
- Use sempre a tool para consultas, nunca invente nÃºmeros

**Guardrails**:
- Grupos com menos de 20 observaÃ§Ãµes sÃ£o filtrados (privacidade)
- Queries limitadas a 10 segundos
- Apenas leitura (SELECT), sem modificaÃ§Ãµes

Seja educado, preciso e Ãºtil!
"""

# Criar agente
agent = create_agent(
    model=model,
    tools=[query_database],  # Adicione generate_chart quando implementar
    system_prompt=SYSTEM_PROMPT,
    name="CreditAnalyticsAgent",
)

# Para testes locais
if __name__ == "__main__":
    # Exemplo de uso
    response = agent.invoke({
        "messages": [
            {"role": "user", "content": "Qual a taxa de inadimplÃªncia mÃ©dia por UF?"}
        ]
    })

    print("\n" + "="*80)
    print("RESPOSTA DO AGENTE:")
    print("="*80)
    print(response["messages"][-1].content)
```

---

### Fase 3: Deploy

#### Arquivo: `langgraph.json`

```json
{
  "dependencies": ["."],
  "graphs": {
    "credit_agent": "./src/agent.py:agent"
  },
  "env": ".env"
}
```

#### Comandos de deploy:

```bash
# 1. Testar localmente
langgraph dev

# 2. Build (se necessÃ¡rio criar Docker image customizada)
langgraph build

# 3. Deploy para LangSmith Cloud
langgraph push
```

---

## ğŸ§ª Testes Sugeridos

### Arquivo: `tests/test_validator.py`

```python
import pytest
from src.utils.sql_validator import sql_validator, SQLValidationError

def test_validate_simple_select():
    sql = 'SELECT * FROM credit_train LIMIT 10'
    valid, formatted = sql_validator.validate(sql)
    assert valid is True
    assert "SELECT" in formatted

def test_block_drop():
    sql = 'DROP TABLE credit_train'
    with pytest.raises(SQLValidationError, match="OperaÃ§Ã£o bloqueada"):
        sql_validator.validate(sql)

def test_block_delete():
    sql = 'DELETE FROM credit_train WHERE "TARGET" = 1'
    with pytest.raises(SQLValidationError, match="OperaÃ§Ã£o bloqueada"):
        sql_validator.validate(sql)

def test_add_default_limit():
    sql = 'SELECT "UF", "IDADE" FROM credit_train'
    valid, formatted = sql_validator.validate(sql)
    assert "LIMIT" in formatted
```

---

## ğŸ¨ SoluÃ§Ã£o de VisualizaÃ§Ãµes com Artifacts

### Por que Artifacts?

Ao gerar grÃ¡ficos, temos um desafio de tokens:
- Uma imagem PNG base64 tem ~119.000 caracteres
- Isso representa ~30.000 tokens no GPT-4
- Custo: ~$0.0012 por imagem se o modelo repetir o base64

### SoluÃ§Ã£o Implementada

Usamos `@tool(response_format="content_and_artifact")` que separa:

**Content** (vai para o modelo):
```python
"VisualizaÃ§Ã£o gerada: Taxa de InadimplÃªncia por UF"  # ~10 tokens
```

**Artifact** (NÃƒO vai para o modelo, mas acessÃ­vel ao UI):
```python
{
    "type": "image",
    "format": "png",
    "mime_type": "image/png",
    "title": "Taxa de InadimplÃªncia por UF",
    "chart_type": "bar",
    "data": "iVBORw0KGgoAAAANSUhEUgAA..."  # 119k chars base64
}
```

### Resultado

âœ… **Economia de tokens**: 99,98% (de 30k para ~10 tokens)
âœ… **Agent Chat UI renderiza automaticamente** o artifact no painel lateral
âœ… **Modelo nÃ£o precisa "ver" a imagem**, apenas sabe que foi gerada

### Como Funciona no Agent

1. User: "Mostre um grÃ¡fico da taxa por UF"
2. Agent chama `query_database` â†’ retorna dados
3. Agent chama `generate_chart` â†’ retorna tuple(content, artifact)
4. LangChain cria ToolMessage com:
   - `.content`: "VisualizaÃ§Ã£o gerada: ..."
   - `.artifact`: {dict com imagem base64}
5. Agent Chat UI pega o artifact e renderiza no painel lateral
6. Agent responde: "Gerei o grÃ¡fico. VocÃª pode visualizÃ¡-lo no painel ao lado."

**Verificado com testes**: src/agent.py:147 - Mensagem 4 (ToolMessage) contÃ©m artifact completo com 119.032 caracteres de base64.

---

## ğŸ“ˆ Melhorias Futuras

### Prioridade Alta
- [x] Implementar `query_database` tool completa com LLM âœ…
- [x] Sistema de retry e auto-correÃ§Ã£o SQL âœ…
- [x] Tool `generate_chart` com matplotlib âœ…
- [ ] Testes unitÃ¡rios completos
- [ ] Cache de queries frequentes (Redis)

### Prioridade MÃ©dia
- [ ] Follow-up questions automÃ¡ticas
- [ ] Human-in-the-loop para queries sensÃ­veis
- [ ] Suporte a mÃºltiplos modelos LLM (via OpenRouter)
- [ ] Deploy no LangSmith Cloud

### Prioridade Baixa
- [ ] Export de resultados (CSV, Excel)
- [ ] HistÃ³rico de conversas persistente
- [ ] Dashboard de mÃ©tricas (p95, taxa erro, custo)
- [ ] IntegraÃ§Ã£o com BI tools

---

## ğŸ¯ Como Usar Este Projeto

### 1. Setup Inicial

```bash
# Clone e instale
git clone <repo>
cd neuro-challange-chatbot
uv sync

# Configure .env
cp .env.example .env
# Edite .env com suas API keys
```

### 2. Desenvolvimento Local

```bash
# Subir banco
docker-compose up -d

# Carregar dados (use --sample 1000 para testes rÃ¡pidos)
uv run python scripts/load_data.py --sample 1000

# Testar conexÃ£o
uv run python -c "from src.utils.db_connection import db_manager; print(db_manager.test_connection())"
```

### 3. Implementar Tools

```bash
# Criar tool query_database
touch src/tools/database_query_tool.py

# Implementar conforme template acima
# Testar isoladamente antes de integrar no agente
```

### 4. Testar Agente

```bash
# Executar agente localmente
uv run python src/agent.py
```

### 5. Deploy

```bash
# Deploy no LangSmith
langgraph push

# Conectar Agent Chat UI
git clone https://github.com/langchain-ai/agent-chat-ui
# Configure e suba
```

---

## ğŸ“Š Arquitetura do Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Agent Chat UI                      â”‚
â”‚              (Next.js - Interface Web)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â”‚ API Calls
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              LangSmith Deployment                    â”‚
â”‚         (Hosting + Observability + Tracing)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â”‚
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           LangChain Agent (src/agent.py)             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  System Prompt + Business Context            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                     â”‚                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚          Tools Dispatcher                    â”‚   â”‚
â”‚  â”‚  â€¢ query_database                            â”‚   â”‚
â”‚  â”‚  â€¢ generate_chart (opcional)                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                       â”‚
        â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tool:            â”‚   â”‚ Tool:            â”‚
â”‚ query_database   â”‚   â”‚ generate_chart   â”‚
â”‚                  â”‚   â”‚                  â”‚
â”‚ 1. NL â†’ SQL      â”‚   â”‚ 1. Recebe dados  â”‚
â”‚ 2. Validate      â”‚   â”‚ 2. Matplotlib    â”‚
â”‚ 3. Execute       â”‚   â”‚ 3. Base64        â”‚
â”‚ 4. Retry         â”‚   â”‚ 4. Return        â”‚
â”‚ 5. Format        â”‚   â”‚                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ SQL Queries
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          PostgreSQL (RDS/Docker)                     â”‚
â”‚                                                      â”‚
â”‚  Table: credit_train (~170k rows)                   â”‚
â”‚  â€¢ REF_DATE, TARGET, SEXO, IDADE                    â”‚
â”‚  â€¢ OBITO, UF, CLASSE_SOCIAL                         â”‚
â”‚  â€¢ Read-only user: chatbot_reader                   â”‚
â”‚  â€¢ Indexes: UF+REF_DATE, SEXO, CLASSE_SOCIAL       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”¥ Comandos RÃ¡pidos de ReferÃªncia

```bash
# Docker
docker-compose up -d                    # Iniciar Postgres
docker-compose logs -f postgres         # Ver logs
docker-compose down -v                  # Resetar tudo

# Python/UV
uv sync                                 # Instalar deps
uv add <package>                        # Adicionar dep
uv run python script.py                 # Executar script
uv run pytest                           # Rodar testes

# Banco de Dados
uv run python scripts/load_data.py      # Carregar dados completos
uv run python scripts/load_data.py --sample 1000  # Amostra

# Desenvolvimento
uv run python src/agent.py              # Testar agente local
langgraph dev                           # Dev server local
langgraph push                          # Deploy LangSmith
```

---

**Ãšltima atualizaÃ§Ã£o**: 2025-10-27
**Status**: âœ… **Projeto 100% funcional** - Tools (query_database + generate_chart) e agente implementados, testados e otimizados com artifacts. Pronto para deploy no LangSmith Cloud.
