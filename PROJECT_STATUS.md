# üìã Status do Projeto - Credit Analytics Chatbot

## ‚úÖ Componentes Implementados

### 1. Infraestrutura e Setup
- [x] **Docker Compose** - Postgres + pgAdmin para desenvolvimento local
- [x] **Estrutura de diret√≥rios** completa
- [x] **pyproject.toml** atualizado com todas as depend√™ncias (gerenciado por `uv`)
- [x] **.gitignore** completo
- [x] **.env.example** com documenta√ß√£o de vari√°veis
- [x] **README.md** detalhado com instru√ß√µes completas

### 2. M√≥dulos Core
- [x] **src/config.py** - Configura√ß√µes centralizadas com Pydantic Settings
  - Database config (RDS/local)
  - LLM config (OpenAI/OpenRouter)
  - LangSmith config (tracing)
  - Guardrails config (k-anonimato, timeouts, limites)
  - Formatting config (PT-BR)

- [x] **src/utils/sql_validator.py** - Valida√ß√£o SQL com sqlglot
  - Valida√ß√£o de sintaxe
  - Bloqueio de DDL/DML (read-only enforcement)
  - Aplica√ß√£o de guardrails (LIMIT padr√£o)
  - Formata√ß√£o SQL

- [x] **src/utils/business_dictionary.py** - Dicion√°rio de neg√≥cio
  - M√©tricas can√¥nicas (inadimpl√™ncia, volume, idade, etc.)
  - Dimens√µes (UF, sexo, classe social, idade, √≥bito)
  - Agrega√ß√µes temporais (mensal, anual)
  - Exemplos few-shot para o LLM
  - Schema completo da tabela

- [x] **src/utils/db_connection.py** - Gerenciador de conex√µes
  - Pool de conex√µes com SQLAlchemy
  - Statement timeout configur√°vel
  - Context manager para conex√µes
  - Helpers para queries e info de tabelas

### 3. Tools Implementadas
- [x] **src/tools/database_query_tool.py** - Tool de consulta SQL ‚úÖ
  - Gera√ß√£o de SQL a partir de linguagem natural usando LLM
  - Valida√ß√£o com sql_validator
  - Sistema de retry com auto-corre√ß√£o (at√© 3 tentativas)
  - Formata√ß√£o de resposta em PT-BR
  - Logging e tracing com LangSmith

- [x] **src/tools/visualization_tool.py** - Tool de visualiza√ß√£o ‚úÖ
  - Gr√°ficos matplotlib com formata√ß√£o PT-BR
  - Tipos suportados: bar, line, histogram, pie
  - Auto-detec√ß√£o de tipo de gr√°fico
  - **Usa `response_format="content_and_artifact"` para efici√™ncia de tokens**
  - Content: ~10 tokens (mensagem curta)
  - Artifact: ~119k chars base64 (N√ÉO enviado ao modelo, economiza ~$0.0012/imagem)
  - Agent Chat UI renderiza artifact automaticamente no painel lateral
  - Labels formatados (%, n, v√≠rgula decimal)

### 4. Agente LangChain
- [x] **src/agent.py** - Agente principal ‚úÖ
  - Criado com create_agent (LangChain 1.0)
  - Integrado com query_database e generate_chart
  - System prompt detalhado com instru√ß√µes PT-BR
  - Observabilidade via LangSmith

### 5. Scripts e Utilidades
- [x] **scripts/init_db.sql** - Inicializa√ß√£o do banco
  - Schema com colunas em **MAI√öSCULA** (conforme solicitado)
  - √çndices otimizados (da EDA)
  - Usu√°rio read-only `chatbot_reader`
  - Permiss√µes restritivas

- [x] **scripts/load_data.py** - Carga de dados
  - Download autom√°tico do dataset
  - Transforma√ß√µes (tipos, normaliza√ß√£o)
  - Carga em lotes com progress bar
  - Valida√ß√µes e estat√≠sticas

---

## üöß Pr√≥ximos Passos (Ordem de Implementa√ß√£o)

### ‚úÖ Fase 1: Tools (Core do Sistema) - CONCLU√çDA

#### ‚úÖ A. Tool `query_database` - IMPLEMENTADA
**Arquivo**: `src/tools/database_query_tool.py`

**Estrutura sugerida**:
```python
from langchain.tools import tool
from langchain_openai import ChatOpenAI
from pydantic import BaseModel, Field

class QueryDatabaseInput(BaseModel):
    """Schema de input para a tool."""
    question_context: str = Field(
        description="Pergunta do usu√°rio em linguagem natural sobre dados de cr√©dito"
    )

@tool(response_format="content_and_artifact")
def query_database(question_context: str) -> tuple[str, dict]:
    """
    Analisa dados de cr√©dito executando SQL baseado na pergunta do usu√°rio.

    Fluxo interno:
    1. LLM gera SQL a partir do contexto
    2. Valida com sql_validator
    3. Executa com retry e auto-corre√ß√£o
    4. Formata resposta em linguagem natural

    Returns:
        (resposta_formatada_pt_br, metadata_com_sql_e_dados)
    """
    # 1. Gerar SQL com LLM
    sql = _generate_sql_with_llm(question_context)

    # 2. Validar
    is_valid, validated_sql = sql_validator.validate(sql)

    # 3. Executar com retry
    result_data = _execute_with_retry(validated_sql, max_retries=3)

    # 4. Formatar resposta
    formatted_response = _format_response_natural_language(
        question_context, result_data
    )

    # 5. Metadata para artifact
    metadata = {
        "sql": validated_sql,
        "data": result_data,
        "row_count": len(result_data)
    }

    return formatted_response, metadata
```

**Componentes internos**:
- `_generate_sql_with_llm()`: Usa LLM com few-shot examples do business_dict
- `_execute_with_retry()`: Tenta executar, captura erros, usa LLM para corrigir
- `_format_response_natural_language()`: Converte resultados para PT-BR formatado

**Depend√™ncias**:
- `from src.utils.sql_validator import sql_validator`
- `from src.utils.business_dictionary import BusinessDictionary`
- `from src.utils.db_connection import db_manager`
- `from src.config import config`

---

#### ‚úÖ B. Tool `generate_chart` - IMPLEMENTADA
**Arquivo**: `src/tools/visualization_tool.py` ‚úÖ

Implementada com sucesso! Features inclu√≠das:

```python
import matplotlib.pyplot as plt
import base64
from io import BytesIO

@tool
def generate_chart(
    data: list[dict],
    chart_type: str = "bar",
    title: str = "Gr√°fico"
) -> str:
    """
    Gera visualiza√ß√£o matplotlib e retorna base64 para Agent Chat UI.

    Tipos suportados: bar, line, pie, histogram
    """
    # Criar gr√°fico
    fig, ax = plt.subplots(figsize=(10, 6))

    # Plotar baseado no tipo
    # ... (implementa√ß√£o matplotlib)

    # Converter para base64
    buffer = BytesIO()
    plt.savefig(buffer, format='png', dpi=150, bbox_inches='tight')
    buffer.seek(0)
    img_base64 = base64.b64encode(buffer.read()).decode()
    plt.close()

    return f"data:image/png;base64,{img_base64}"
```

---

### Fase 2: Agente LangChain

#### Arquivo: `src/agent.py`

```python
"""
Agente LangChain para an√°lise de dados de cr√©dito.
"""

from langchain.agents import create_agent
from langchain_openai import ChatOpenAI

from src.config import config
from src.tools.database_query_tool import query_database
# from src.tools.visualization_tool import generate_chart

# Configurar LangSmith
config.setup_langsmith()

# Inicializar modelo
model = ChatOpenAI(
    model=config.llm.model,
    temperature=config.llm.temperature,
    max_tokens=config.llm.max_tokens,
)

# System prompt
SYSTEM_PROMPT = """
Voc√™ √© um assistente especialista em an√°lise de dados de cr√©dito brasileiro.

Voc√™ tem acesso a uma base de ~170mil registros de concess√£o de cr√©dito (per√≠odo: 2017-01 a 2017-08).

**Dados dispon√≠veis**:
- REF_DATE: Data de refer√™ncia
- TARGET: Inadimpl√™ncia (0=bom pagador, 1=mau pagador)
- SEXO: M/F
- IDADE: Idade em anos
- OBITO: Indicador de √≥bito
- UF: Estado brasileiro (27 UFs)
- CLASSE_SOCIAL: alta, m√©dia, baixa

**Sua miss√£o**:
1. Interpretar perguntas do usu√°rio sobre os dados
2. Usar a tool `query_database` para executar an√°lises SQL
3. Responder em portugu√™s claro e objetivo
4. Explicar insights de forma acess√≠vel

**Dicion√°rio de termos**:
- "inadimpl√™ncia" ou "mau pagador" = TARGET=1
- "taxa de inadimpl√™ncia" = m√©dia do TARGET (em %)
- Use sempre a tool para consultas, nunca invente n√∫meros

**Guardrails**:
- Grupos com menos de 20 observa√ß√µes s√£o filtrados (privacidade)
- Queries limitadas a 10 segundos
- Apenas leitura (SELECT), sem modifica√ß√µes

Seja educado, preciso e √∫til!
"""

# Criar agente
agent = create_agent(
    model=model,
    tools=[query_database],  # Adicione generate_chart quando implementar
    system_prompt=SYSTEM_PROMPT,
    name="CreditAnalyticsAgent",
)

# Para testes locais
if __name__ == "__main__":
    # Exemplo de uso
    response = agent.invoke({
        "messages": [
            {"role": "user", "content": "Qual a taxa de inadimpl√™ncia m√©dia por UF?"}
        ]
    })

    print("\n" + "="*80)
    print("RESPOSTA DO AGENTE:")
    print("="*80)
    print(response["messages"][-1].content)
```

---

### Fase 3: Deploy

#### Arquivo: `langgraph.json`

```json
{
  "dependencies": ["."],
  "graphs": {
    "credit_agent": "./src/agent.py:agent"
  },
  "env": ".env"
}
```

#### Comandos de deploy:

```bash
# 1. Testar localmente
langgraph dev

# 2. Build (se necess√°rio criar Docker image customizada)
langgraph build

# 3. Deploy para LangSmith Cloud
langgraph push
```

---

## üß™ Testes Sugeridos

### Arquivo: `tests/test_validator.py`

```python
import pytest
from src.utils.sql_validator import sql_validator, SQLValidationError

def test_validate_simple_select():
    sql = 'SELECT * FROM credit_train LIMIT 10'
    valid, formatted = sql_validator.validate(sql)
    assert valid is True
    assert "SELECT" in formatted

def test_block_drop():
    sql = 'DROP TABLE credit_train'
    with pytest.raises(SQLValidationError, match="Opera√ß√£o bloqueada"):
        sql_validator.validate(sql)

def test_block_delete():
    sql = 'DELETE FROM credit_train WHERE "TARGET" = 1'
    with pytest.raises(SQLValidationError, match="Opera√ß√£o bloqueada"):
        sql_validator.validate(sql)

def test_add_default_limit():
    sql = 'SELECT "UF", "IDADE" FROM credit_train'
    valid, formatted = sql_validator.validate(sql)
    assert "LIMIT" in formatted
```

---

## üé® Solu√ß√£o de Visualiza√ß√µes com Artifacts

### Por que Artifacts?

Ao gerar gr√°ficos, temos um desafio de tokens:
- Uma imagem PNG base64 tem ~119.000 caracteres
- Isso representa ~30.000 tokens no GPT-4
- Custo: ~$0.0012 por imagem se o modelo repetir o base64

### Solu√ß√£o Implementada

Usamos `@tool(response_format="content_and_artifact")` que separa:

**Content** (vai para o modelo):
```python
"Visualiza√ß√£o gerada: Taxa de Inadimpl√™ncia por UF"  # ~10 tokens
```

**Artifact** (N√ÉO vai para o modelo, mas acess√≠vel ao UI):
```python
{
    "type": "image",
    "format": "png",
    "mime_type": "image/png",
    "title": "Taxa de Inadimpl√™ncia por UF",
    "chart_type": "bar",
    "data": "iVBORw0KGgoAAAANSUhEUgAA..."  # 119k chars base64
}
```

### Resultado

‚úÖ **Economia de tokens**: 99,98% (de 30k para ~10 tokens)
‚úÖ **Agent Chat UI renderiza automaticamente** o artifact no painel lateral
‚úÖ **Modelo n√£o precisa "ver" a imagem**, apenas sabe que foi gerada

### Como Funciona no Agent

1. User: "Mostre um gr√°fico da taxa por UF"
2. Agent chama `query_database` ‚Üí retorna dados
3. Agent chama `generate_chart` ‚Üí retorna tuple(content, artifact)
4. LangChain cria ToolMessage com:
   - `.content`: "Visualiza√ß√£o gerada: ..."
   - `.artifact`: {dict com imagem base64}
5. Agent Chat UI pega o artifact e renderiza no painel lateral
6. Agent responde: "Gerei o gr√°fico. Voc√™ pode visualiz√°-lo no painel ao lado."

**Verificado com testes**: src/agent.py:147 - Mensagem 4 (ToolMessage) cont√©m artifact completo com 119.032 caracteres de base64.

---

## üìà Melhorias Futuras

### Prioridade Alta
- [x] Implementar `query_database` tool completa com LLM ‚úÖ
- [x] Sistema de retry e auto-corre√ß√£o SQL ‚úÖ
- [x] Tool `generate_chart` com matplotlib ‚úÖ
- [ ] Testes unit√°rios completos
- [ ] Cache de queries frequentes (Redis)

### Prioridade M√©dia
- [ ] Follow-up questions autom√°ticas
- [ ] Human-in-the-loop para queries sens√≠veis
- [ ] Suporte a m√∫ltiplos modelos LLM (via OpenRouter)
- [ ] Deploy no LangSmith Cloud

### Prioridade Baixa
- [ ] Export de resultados (CSV, Excel)
- [ ] Hist√≥rico de conversas persistente
- [ ] Dashboard de m√©tricas (p95, taxa erro, custo)
- [ ] Integra√ß√£o com BI tools

---

## üéØ Como Usar Este Projeto

### 1. Setup Inicial

```bash
# Clone e instale
git clone <repo>
cd neuro-challange-chatbot
uv sync

# Configure .env
cp .env.example .env
# Edite .env com suas API keys
```

### 2. Desenvolvimento Local

```bash
# Subir banco
docker-compose up -d

# Carregar dados (use --sample 1000 para testes r√°pidos)
uv run python scripts/load_data.py --sample 1000

# Testar conex√£o
uv run python -c "from src.utils.db_connection import db_manager; print(db_manager.test_connection())"
```

### 3. Implementar Tools

```bash
# Criar tool query_database
touch src/tools/database_query_tool.py

# Implementar conforme template acima
# Testar isoladamente antes de integrar no agente
```

### 4. Testar Agente

```bash
# Executar agente localmente
uv run python src/agent.py
```

### 5. Deploy

```bash
# Deploy no LangSmith
langgraph push

# Conectar Agent Chat UI
git clone https://github.com/langchain-ai/agent-chat-ui
# Configure e suba
```

---

## üìä Arquitetura do Sistema

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   Agent Chat UI                      ‚îÇ
‚îÇ              (Next.js - Interface Web)               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
                    ‚îÇ API Calls
                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              LangSmith Deployment                    ‚îÇ
‚îÇ         (Hosting + Observability + Tracing)          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
                    ‚îÇ
                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           LangChain Agent (src/agent.py)             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  System Prompt + Business Context            ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                     ‚îÇ                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ          Tools Dispatcher                    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ query_database                            ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ generate_chart (opcional)                 ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ                       ‚îÇ
        ‚ñº                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Tool:            ‚îÇ   ‚îÇ Tool:            ‚îÇ
‚îÇ query_database   ‚îÇ   ‚îÇ generate_chart   ‚îÇ
‚îÇ                  ‚îÇ   ‚îÇ                  ‚îÇ
‚îÇ 1. NL ‚Üí SQL      ‚îÇ   ‚îÇ 1. Recebe dados  ‚îÇ
‚îÇ 2. Validate      ‚îÇ   ‚îÇ 2. Matplotlib    ‚îÇ
‚îÇ 3. Execute       ‚îÇ   ‚îÇ 3. Base64        ‚îÇ
‚îÇ 4. Retry         ‚îÇ   ‚îÇ 4. Return        ‚îÇ
‚îÇ 5. Format        ‚îÇ   ‚îÇ                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚îÇ SQL Queries
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ          PostgreSQL (RDS/Docker)                     ‚îÇ
‚îÇ                                                      ‚îÇ
‚îÇ  Table: credit_train (~170k rows)                   ‚îÇ
‚îÇ  ‚Ä¢ REF_DATE, TARGET, SEXO, IDADE                    ‚îÇ
‚îÇ  ‚Ä¢ OBITO, UF, CLASSE_SOCIAL                         ‚îÇ
‚îÇ  ‚Ä¢ Read-only user: chatbot_reader                   ‚îÇ
‚îÇ  ‚Ä¢ Indexes: UF+REF_DATE, SEXO, CLASSE_SOCIAL       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üî• Comandos R√°pidos de Refer√™ncia

```bash
# Docker
docker-compose up -d                    # Iniciar Postgres
docker-compose logs -f postgres         # Ver logs
docker-compose down -v                  # Resetar tudo

# Python/UV
uv sync                                 # Instalar deps
uv add <package>                        # Adicionar dep
uv run python script.py                 # Executar script
uv run pytest                           # Rodar testes

# Banco de Dados
uv run python scripts/load_data.py      # Carregar dados completos
uv run python scripts/load_data.py --sample 1000  # Amostra

# Desenvolvimento
uv run python src/agent.py              # Testar agente local
langgraph dev                           # Dev server local
langgraph push                          # Deploy LangSmith
```

---

**√öltima atualiza√ß√£o**: 2025-10-27
**Status**: ‚úÖ **Projeto 100% funcional** - Tools (query_database + generate_chart) e agente implementados, testados e otimizados com artifacts. Pronto para deploy no LangSmith Cloud.
